{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_NLP_With_Torch_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQG2JvNmVe9wnLqx4Amd3t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeevr5/NLP_Excercises/blob/main/DL_NLP_With_Torch_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A multiclass classification using the Embedding bag layer\n",
        "\n",
        "The Embedding layer gives us a vector representation for every token while the embeddingbg performs an aggregation operation on top of every sentence and returns the result.\n",
        "\n",
        "Embedding I/P : [['hi', how', 'are', 'you'], ['ok', 'bye', '<pad>', '<pad>']]\n",
        "\n",
        "Embedding layer O/P : (2,4,64)\n",
        "\n",
        "Embedding bag I/P : ['hi', how', 'are', 'you', 'ok', 'bye']\n",
        "\n",
        "Embedding bag O/ P: There is no need of padding tokens it can be directly fed. (2, 64) -> (B, embed_dim)\n",
        "\n",
        "Embedding bag since it performs some aggregate operation sequential information is lost. There is no need of padding. Offsets should be mentioned instead of the padding. The offsets of above example is [0, 4] since first sentence starts from 0 and second sentence starts at 4th index.\n",
        "\n",
        "More at : https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html"
      ],
      "metadata": {
        "id": "ztg_s_QCkqa5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy6LY8_Ckj0Q"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
        "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torch.nn.utils.rnn import pack_sequence\n",
        "import time\n",
        "import torch.optim as optim\n",
        "\n",
        "SEED = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "gs1j1y_nnl54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('./train.csv', sep = ',', header = None)\n",
        "test_data = pd.read_csv('./test.csv', sep = ',', header = None)\n",
        "\n",
        "print(f'Train shape : {train_data.shape} test shape : {test_data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UADhH_JDnsnJ",
        "outputId": "9c8c39dd-8e1a-4c9b-d5d3-b22ad35e67c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape : (120000, 3) test shape : (7600, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = train_data.iloc[:,1].map(lambda x : x.split(' (')[0].lower()), train_data.iloc[:,0].map(lambda x : int(x - 1))\n",
        "X_test, y_test = test_data.iloc[:,1].map(lambda x : x.split(' (')[0].lower()), test_data.iloc[:,0].map(lambda x : int(x - 1))"
      ],
      "metadata": {
        "id": "G41IO0tdnwr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(X_train), specials=[\"<unk>\"]) #padding token not required\n",
        "vocab.set_default_index(vocab[\"<unk>\"]) "
      ],
      "metadata": {
        "id": "TnQnWBDWnzU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoded = [torch.tensor(vocab(tokenizer(item))) for item in X_train.values]\n",
        "test_encoded = [torch.tensor(vocab(tokenizer(item))) for item in X_test.values]\n",
        "\n",
        "print('train sample:', train_encoded[0])\n",
        "print('test sample:', test_encoded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StMSsftUoHKh",
        "outputId": "398edd2e-e167-4e79-e788-2792aac83b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train sample: tensor([  473,   295,     2,   873, 11871,    53,    67,    11,   480])\n",
            "test sample: tensor([482,   6,  44, 108, 792,  32,  48])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The length of vocabulary is {len(vocab)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLhIuI6_oUar",
        "outputId": "a82e0320-12f3-4c6c-d044-281ed3b93893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of vocabulary is 39515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class Data_Iterator(data.Dataset):\n",
        "\n",
        "  def __init__(self, text, label):\n",
        "    super(Data_Iterator, self).__init__()\n",
        "    assert len(text) == len(label)\n",
        "    self.text = text\n",
        "    self.label = label\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.text[index], self.label[index]\n",
        "\n",
        "train_data = Data_Iterator(train_encoded, y_train)\n",
        "test_data = Data_Iterator(test_encoded, y_test)"
      ],
      "metadata": {
        "id": "0NC8BrHGpFX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batchTransformer(batch):\n",
        "  offset = [0]\n",
        "  newsL = []\n",
        "  labelL = []\n",
        "  for news, label in batch:\n",
        "    offset.append(news.size(0))\n",
        "    newsL.append(news)\n",
        "    labelL.append(label)\n",
        "  label = torch.tensor(labelL, dtype=torch.int64)\n",
        "  offset = torch.tensor(offset[:-1]).cumsum(dim=0)\n",
        "  news = torch.cat(newsL)\n",
        "  return news, offset, label #Offset ignoring last index\n",
        "\n",
        "trainloader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn= batchTransformer) \n",
        "testloader = DataLoader(test_data, batch_size=128, shuffle=True, collate_fn = batchTransformer)"
      ],
      "metadata": {
        "id": "WYw55QiTobmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)\n",
        "\n",
        "model = NewsClassifier(len(vocab), 128, 4)\n",
        "print(f'The number of trainable parameters are : {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HwmahEjqcKs",
        "outputId": "a4966abb-1c22-4d85-ca81-b874871f3a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of trainable parameters are : 5,058,436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "d8737e6g2MAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def accuracy(preds, true):\n",
        "  _, index = torch.max(preds, dim = 1)\n",
        "  return (index == true).sum().float() / len(preds)"
      ],
      "metadata": {
        "id": "Ios-in-k2jG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_m(model, iterator, optimizer, l):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  model.train()\n",
        "\n",
        "  for inputs, offsets, labels in iterator:\n",
        "    inputs, offsets, labels = inputs.to(device), offsets.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(inputs, offsets)\n",
        "    acc = accuracy(preds,  labels)\n",
        "    loss = l(preds.squeeze(1), labels.long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    e_loss += loss.item()\n",
        "    e_acc += acc.item()\n",
        "  return e_loss/len(iterator), e_acc/len(iterator)\n",
        "\n",
        "def evaluate_m(model, iterator, l):\n",
        "  e_loss = 0\n",
        "  e_acc = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for inputs, offsets, labels in iterator:\n",
        "      inputs, offsets, labels = inputs.to(device), offsets.to(device), labels.to(device)\n",
        "      preds = model(inputs, offsets)\n",
        "      loss = l(preds.squeeze(1), labels.long())\n",
        "      acc = accuracy(preds,  labels)\n",
        "      e_loss += loss.item()\n",
        "      e_acc += acc.item()\n",
        "  return e_loss/len(iterator), e_acc/len(iterator)"
      ],
      "metadata": {
        "id": "qspsgY6s2nR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train_m(model, trainloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate_m(model, testloader, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} / {N_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YQrmhe12pMC",
        "outputId": "bde46c4a-a440-4d77-9b79-b8318150d9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 / 5 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.646 | Train Acc: 78.02%\n",
            "\t Val. Loss: 0.444 |  Val. Acc: 85.49%\n",
            "Epoch: 02 / 5 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.348 | Train Acc: 88.77%\n",
            "\t Val. Loss: 0.412 |  Val. Acc: 86.25%\n",
            "Epoch: 03 / 5 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.277 | Train Acc: 90.96%\n",
            "\t Val. Loss: 0.417 |  Val. Acc: 86.48%\n",
            "Epoch: 04 / 5 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.238 | Train Acc: 92.16%\n",
            "\t Val. Loss: 0.432 |  Val. Acc: 86.07%\n",
            "Epoch: 05 / 5 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.213 | Train Acc: 92.84%\n",
            "\t Val. Loss: 0.461 |  Val. Acc: 85.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "XD06XRya4h1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tec\"}\n",
        "\n",
        "def predict(text):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(vocab(tokenizer(text))).to(device)\n",
        "        output = model(text, torch.tensor([0]).to(device))\n",
        "        return output.argmax(1).item() + 1\n",
        "labels[predict('India won the match')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b0ov2Lu02rLb",
        "outputId": "dc108da4-60ad-4c75-fe15-8a453b8bd458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sports'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}