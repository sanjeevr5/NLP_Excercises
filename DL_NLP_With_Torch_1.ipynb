{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_NLP_With_Torch_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzJzB9qrriyH4XQXfv6T8F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6d36e102cdb4366abd7fd5125c3d110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d234406d4b094806996181726aae65f3",
              "IPY_MODEL_3a5ee797cc5c4eb2b3a87a9162fad531",
              "IPY_MODEL_a7d52880dcf64572a48da3f267b90189"
            ],
            "layout": "IPY_MODEL_db96080ea14942aaaa5fac2e8c0b39ba"
          }
        },
        "d234406d4b094806996181726aae65f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbdfb16165164c49a5691847ad4eff45",
            "placeholder": "​",
            "style": "IPY_MODEL_71892773b69e49e88f1467a8afd88cf0",
            "value": "100%"
          }
        },
        "3a5ee797cc5c4eb2b3a87a9162fad531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4f9661106e4813b64f9f160179c9ad",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23106881df0141b58317c7fb30cc1943",
            "value": 25000
          }
        },
        "a7d52880dcf64572a48da3f267b90189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_120fb95101da48f6950e6cb6719d384c",
            "placeholder": "​",
            "style": "IPY_MODEL_cbd304db38d544f68e36ca3fcd66ef47",
            "value": " 25000/25000 [00:01&lt;00:00, 25537.52it/s]"
          }
        },
        "db96080ea14942aaaa5fac2e8c0b39ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbdfb16165164c49a5691847ad4eff45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71892773b69e49e88f1467a8afd88cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac4f9661106e4813b64f9f160179c9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23106881df0141b58317c7fb30cc1943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "120fb95101da48f6950e6cb6719d384c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd304db38d544f68e36ca3fcd66ef47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeevr5/NLP_Excercises/blob/main/DL_NLP_With_Torch_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binary classification problem using RNNs\n",
        "\n",
        "This exercise is performed on IMDB movie reviews dataset. There are two sentiments here 0. Negative 1. Positive. \n",
        "\n",
        "<b> Architecture details </b>\n",
        "\n",
        "1. We shall train our embedding representations.\n",
        "2. Using an RNN architecture with pad_sequences, pack_pad_sequences and pad_packed_sequences.\n",
        "3. Dataloaders to have generator kind of data feed to the model.\n",
        "4. The sequences should not be too long. There should be a clipping factor and hence choose the vocabulary wisely.LSTMs cannot handle very long input sequence.\n",
        "5. Passing outputs of output layer or the hidden state to the dense layer."
      ],
      "metadata": {
        "id": "WcXdNoqpCO-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the data"
      ],
      "metadata": {
        "id": "_vy2VG0zCij6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4fSbz_pCI9P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!pip install bpemb\n",
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xvzf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the essentials"
      ],
      "metadata": {
        "id": "7j8a47yRCkQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED= 20\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)"
      ],
      "metadata": {
        "id": "v9_P9uMgCbYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer and pre-processing\n",
        "\n",
        "A minimal pre-processing to retain only characters."
      ],
      "metadata": {
        "id": "xrKPOdUDCmOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import re\n",
        "\n",
        "tokenizer = lambda x : [token for token in re.sub(r'[^a-z\\s]', '', x.lower()).split() if token !=' ']"
      ],
      "metadata": {
        "id": "7_zlL9HXCoRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = [[(tokenizer(open(f'/content/aclImdb/train/{cat}/{file}', 'r').read()), 1 if cat == 'pos' else 0) for file in os.listdir(f'/content/aclImdb/train/{cat}')] for cat in ('pos', 'neg')]\n",
        "test_list = [[(tokenizer(open(f'/content/aclImdb/test/{cat}/{file}', 'r').read()) ,1 if cat == 'pos' else 0) for file in os.listdir(f'/content/aclImdb/test/{cat}')] for cat in ('pos', 'neg')]\n",
        "\n",
        "train_list = [*train_list[0], *train_list[1]]\n",
        "test_list = [*test_list[0], *test_list[1]]"
      ],
      "metadata": {
        "id": "ZjCjRDjpCo8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sample train data', train_list[0]) #review tokenized, label\n",
        "print('Sample test data', test_list[0]) #review tokenized, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRi1cjOzC0eC",
        "outputId": "db78c095-455b-483b-8c4c-41756de965f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample train data (['this', 'is', 'the', 'best', 'movie', 'ive', 'come', 'across', 'in', 'a', 'long', 'while', 'not', 'only', 'is', 'this', 'the', 'best', 'movie', 'of', 'its', 'kindschool', 'shootingthe', 'way', 'ben', 'cocciothe', 'director', 'decided', 'to', 'film', 'it', 'was', 'magnificent', 'he', 'filmed', 'it', 'using', 'teenage', 'actors', 'who', 'were', 'still', 'attending', 'high', 'school', 'he', 'filmed', 'it', 'in', 'the', 'actors', 'own', 'rooms', 'and', 'used', 'the', 'actors', 'real', 'parents', 'as', 'their', 'parents', 'in', 'the', 'film', 'also', 'the', 'actors', 'were', 'filming', 'too', 'using', 'camcorders', 'making', 'it', 'seem', 'much', 'more', 'like', 'a', 'video', 'diary', 'it', 'is', 'almost', 'artfulif', 'that', 'is', 'indeed', 'a', 'wordthere', 'are', 'a', 'few', 'slip', 'ups', 'however', 'for', 'example', 'when', 'cal', 'calls', 'brads', 'land', 'rover', 'a', 'range', 'roveror', 'vice', 'versa', 'its', 'been', 'awhile', 'since', 'ive', 'seen', 'it'], 1)\n",
            "Sample test data (['i', 'dont', 'know', 'whether', 'this', 'film', 'hits', 'my', 'heart', 'the', 'way', 'it', 'does', 'because', 'of', 'the', 'feelings', 'of', 'friendship', 'love', 'closeness', 'to', 'others', 'or', 'the', 'warmth', 'of', 'that', 'transformation', 'babettes', 'cooking', 'creates', 'but', 'when', 'the', 'feast', 'starts', 'and', 'for', 'the', 'rest', 'of', 'the', 'movie', 'i', 'choke', 'up', 'often', 'br', 'br', 'yes', 'this', 'is', 'a', 'feelgood', 'movie', 'but', 'without', 'a', 'speck', 'of', 'mawkishness', 'or', 'facile', 'sentimentality', 'please', 'note', 'that', 'elements', 'of', 'the', 'plot', 'are', 'discussed', 'babettes', 'feast', 'tells', 'its', 'story', 'with', 'restraint', 'and', 'care', 'and', 'it', 'lets', 'us', 'discover', 'for', 'ourselves', 'the', 'values', 'of', 'grace', 'and', 'love', 'all', 'we', 'need', 'to', 'know', 'is', 'that', 'babette', 'harsant', 'stephane', 'audran', 'was', 'a', 'french', 'refugee', 'who', 'was', 'given', 'shelter', 'by', 'two', 'aging', 'sisters', 'in', 'a', 'tiny', 'community', 'on', 'the', 'coast', 'of', 'jutland', 'the', 'sisters', 'lead', 'what', 'remains', 'of', 'their', 'fathers', 'flock', 'he', 'was', 'a', 'pastor', 'of', 'conviction', 'who', 'taught', 'that', 'salvation', 'comes', 'through', 'selfdenial', 'the', 'sisters', 'made', 'their', 'sacrifices', 'to', 'duty', 'and', 'faith', 'those', 'who', 'still', 'remain', 'honor', 'the', 'now', 'long', 'dead', 'pastors', 'teachings', 'and', 'his', 'spiritual', 'guidance', 'still', 'as', 'they', 'have', 'grown', 'older', 'the', 'tiny', 'community', 'has', 'become', 'querulous', 'and', 'argumentative', 'the', 'sisters', 'do', 'what', 'they', 'can', 'for', 'the', 'pastors', 'th', 'birthday', 'babette', 'wishes', 'to', 'cook', 'the', 'dinner', 'for', 'the', 'small', 'group', 'the', 'sisters', 'will', 'invite', 'the', 'sisters', 'reluctantly', 'agree', 'but', 'when', 'they', 'see', 'the', 'supplies', 'babette', 'has', 'ordered', 'they', 'and', 'their', 'guests', 'become', 'uneasy', 'they', 'are', 'used', 'to', 'the', 'communitys', 'usual', 'fare', 'of', 'dried', 'cod', 'boiled', 'and', 'a', 'soup', 'made', 'of', 'bread', 'water', 'and', 'a', 'little', 'ale', 'even', 'though', 'babette', 'over', 'time', 'has', 'made', 'improvements', 'what', 'they', 'are', 'seeing', 'now', 'seems', 'close', 'to', 'godlessness', 'at', 'the', 'dinner', 'also', 'will', 'be', 'a', 'visitor', 'general', 'lorens', 'lowenhielm', 'who', 'years', 'earlier', 'had', 'chosen', 'ambition', 'over', 'his', 'love', 'for', 'one', 'of', 'the', 'sisters', 'br', 'br', 'what', 'do', 'we', 'experience', 'there', 'is', 'the', 'austerity', 'of', 'the', 'aging', 'communitys', 'faith', 'and', 'the', 'stone', 'windswept', 'cottages', 'they', 'live', 'in', 'there', 'is', 'the', 'warmth', 'by', 'candlelight', 'of', 'the', 'sisters', 'small', 'crowded', 'dining', 'room', 'and', 'then', 'there', 'is', 'the', 'transforming', 'power', 'of', 'babettes', 'artistry', 'as', 'we', 'watch', 'her', 'cook', 'watch', 'erik', 'a', 'young', 'boy', 'helping', 'her', 'serve', 'and', 'pour', 'and', 'watch', 'the', 'old', 'parishioners', 'with', 'the', 'help', 'of', 'fine', 'wine', 'and', 'exquisite', 'cooking', 'gradually', 'rediscover', 'their', 'community', 'and', 'love', 'and', 'friendship', 'the', 'general', 'serves', 'as', 'our', 'unexpected', 'guide', 'because', 'he', 'is', 'the', 'only', 'one', 'who', 'knows', 'what', 'extraordinary', 'dishes', 'they', 'are', 'eating', 'the', 'general', 'tells', 'a', 'story', 'to', 'his', 'uncomprehending', 'dinner', 'companions', 'a', 'story', 'about', 'a', 'famed', 'woman', 'who', 'was', 'the', 'exemplary', 'chef', 'at', 'the', 'famed', 'caf', 'anglais', 'in', 'paris', 'this', 'woman', 'this', 'head', 'chef', 'had', 'the', 'ability', 'to', 'transform', 'a', 'dinner', 'into', 'a', 'kind', 'of', 'love', 'affaira', 'love', 'affair', 'that', 'made', 'no', 'distinction', 'between', 'bodily', 'appetite', 'and', 'spiritual', 'appetite', 'he', 'too', 'is', 'being', 'transformed', 'into', 'a', 'man', 'who', 'will', 'accept', 'what', 'he', 'has', 'become', 'and', 'yet', 'will', 'always', 'know', 'the', 'value', 'and', 'the', 'love', 'of', 'what', 'long', 'ago', 'he', 'chose', 'not', 'to', 'accept', 'an', 'old', 'couple', 'kiss', 'two', 'old', 'men', 'remember', 'past', 'friendships', 'and', 'babette', 'who', 'spent', 'all', 'that', 'she', 'had', 'won', 'in', 'a', 'lottery', 'on', 'this', 'dinner', 'has', 'had', 'an', 'opportunity', 'to', 'be', 'the', 'artist', 'she', 'once', 'was', 'in', 'france', 'an', 'opportunity', 'she', 'accepted', 'with', 'love', 'and', 'friendship', 'br', 'br', 'babette', 'now', 'as', 'poor', 'as', 'she', 'was', 'when', 'she', 'arrived', 'penniless', 'years', 'earlier', 'will', 'continue', 'with', 'the', 'sisters', 'the', 'general', 'in', 'a', 'carriage', 'with', 'his', 'aunt', 'returns', 'to', 'her', 'estate', 'and', 'the', 'elderly', 'guests', 'leave', 'the', 'sisters', 'home', 'to', 'return', 'to', 'their', 'own', 'cottages', 'they', 'pause', 'and', 'look', 'at', 'the', 'clear', 'night', 'sky', 'and', 'the', 'stars', 'overhead', 'they', 'spontaneously', 'hold', 'hands', 'in', 'a', 'circle', 'and', 'dance', 'and', 'sing', 'this', 'hymn', 'br', 'br', 'the', 'clock', 'strikes', 'and', 'time', 'goes', 'by', 'eternity', 'is', 'nigh', 'let', 'us', 'use', 'this', 'time', 'to', 'try', 'to', 'serve', 'the', 'lord', 'with', 'heart', 'and', 'mind', 'so', 'that', 'our', 'true', 'home', 'we', 'shall', 'find', 'so', 'that', 'our', 'true', 'home', 'we', 'shall', 'find', 'br', 'br', 'they', 'smile', 'at', 'each', 'other', 'all', 'has', 'been', 'reconciled', 'br', 'br', 'babettes', 'feast', 'is', 'a', 'wonderful', 'movie', 'full', 'of', 'restrained', 'emotion', 'unspoken', 'understandings', 'wisdomand', 'of', 'course', 'a', 'meal', 'that', 'will', 'leave', 'you', 'with', 'a', 'growling', 'stomach', 'as', 'you', 'exit', 'the', 'theater', 'if', 'you', 'win', 'a', 'lottery', 'so', 'you', 'could', 'afford', 'what', 'babette', 'created', 'and', 'have', 'her', 'skill', 'and', 'artistry', 'heres', 'what', 'she', 'served', 'br', 'br', 'potage', 'a', 'la', 'tortue', 'a', 'rich', 'turtle', 'soup', 'served', 'with', 'amontillado', 'sherry', 'blinis', 'demidoff', 'au', 'caviar', 'small', 'buckwheat', 'pancakes', 'with', 'sour', 'cream', 'and', 'caviar', 'served', 'with', 'veuve', 'clicquot', 'champagne', 'cailles', 'en', 'sarcophage', 'with', 'sauce', 'perigourdine', 'boned', 'quail', 'stuffed', 'with', 'foie', 'gras', 'and', 'truffle', 'in', 'puff', 'pastry', 'with', 'truffle', 'sauce', 'enriched', 'with', 'madeira', 'served', 'with', 'clos', 'de', 'vougeot', 'a', 'fine', 'burgundy', 'salade', 'cheese', 'and', 'fresh', 'fruit', 'baba', 'au', 'rhum', 'with', 'glacee', 'fruit', 'and', 'fresh', 'figs', 'coffee', 'and', 'a', 'fine', 'brandy'], 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build vocabulary"
      ],
      "metadata": {
        "id": "sGvWU0FJDDYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "def vocabGenerator(lst):\n",
        "  for data, _ in tqdm_notebook(lst):\n",
        "    yield data\n",
        "\n",
        "vocab = build_vocab_from_iterator(vocabGenerator(train_list), min_freq = 5, specials = ['<unk>', '<pad>'], max_tokens = 20002, special_first = False)\n",
        "vocab.set_default_index(vocab['<unk>']) #unknown tokens will have this index\n",
        "print(f'The length of the vocabulary is', len(vocab)) #max tokens 20k + 2 spl tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "a6d36e102cdb4366abd7fd5125c3d110",
            "d234406d4b094806996181726aae65f3",
            "3a5ee797cc5c4eb2b3a87a9162fad531",
            "a7d52880dcf64572a48da3f267b90189",
            "db96080ea14942aaaa5fac2e8c0b39ba",
            "fbdfb16165164c49a5691847ad4eff45",
            "71892773b69e49e88f1467a8afd88cf0",
            "ac4f9661106e4813b64f9f160179c9ad",
            "23106881df0141b58317c7fb30cc1943",
            "120fb95101da48f6950e6cb6719d384c",
            "cbd304db38d544f68e36ca3fcd66ef47"
          ]
        },
        "id": "R4b5xI_gDGqu",
        "outputId": "89b34a89-836b-4e1f-b3c5-cda20691e774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6d36e102cdb4366abd7fd5125c3d110"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the vocabulary is 20002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loader with padding"
      ],
      "metadata": {
        "id": "rtUaddNODTFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
        "\n",
        "def rnnInputsCollate(batch, clip = 256, pad_value = vocab['<pad>']):\n",
        "  batch = sorted(batch, key = lambda x : len(x[0]), reverse = True)\n",
        "  review = [torch.tensor(vocab(review))[:clip] for review, _ in batch]\n",
        "  lens = torch.LongTensor([len(r) for r in review])\n",
        "  review_padded = pad_sequence(review, padding_value = pad_value)\n",
        "  label = torch.LongTensor([label for _, label in batch])\n",
        "  return review_padded, lens, label\n",
        "\n",
        "trainDataloader = DataLoader(train_list, batch_size = 32, shuffle = True, collate_fn = rnnInputsCollate)\n",
        "testDataloader = DataLoader(test_list, batch_size = 128, shuffle = True, collate_fn = rnnInputsCollate)"
      ],
      "metadata": {
        "id": "-Iw9hN9UDVdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A general RNN class to accomodate different configurations\n",
        "\n",
        "n_classes is 1 for binary problems"
      ],
      "metadata": {
        "id": "pMo3HyQeDds8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBClassifier(nn.Module):\n",
        "  def __init__(self, vocab_weights, rnn_type, vocab_size, n_classes, embed_size, rnn_units, \n",
        "               n_layers, bi_dir, rnn_drop, drop_r, padding_index, use_output = True):\n",
        "    super().__init__()\n",
        "    self.rnn_units = rnn_units\n",
        "    self.n_classes = n_classes\n",
        "    self.rnn_type = rnn_type\n",
        "    self.bi_dir = bi_dir\n",
        "    self.n_layers = n_layers\n",
        "    self.use_output = use_output\n",
        "    if vocab_weights:\n",
        "      self.embedding = nn.Embedding.from_pretrained(torch.as_tensor(vocab_weights))\n",
        "    else:\n",
        "      self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx = padding_index)\n",
        "    if rnn_type == 'LSTM':\n",
        "      self.rnn = nn.LSTM(embed_size, rnn_units, num_layers = n_layers, bidirectional = bi_dir, dropout = rnn_drop)\n",
        "    elif rnn_type == 'GRU':\n",
        "      self.rnn = nn.GRU(embed_size, rnn_units, num_layers = n_layers, bidirectional = bi_dir, dropout = rnn_drop)\n",
        "    else:\n",
        "      raise NotImplementError('Only LSTM and GRU supported!')\n",
        "    self.fc = nn.Linear(2 * rnn_units if bi_dir else rnn_units, self.n_classes)\n",
        "    self.drp = nn.Dropout(drop_r)\n",
        "  \n",
        "  def forward(self, data, lens):\n",
        "    #-------------#\n",
        "    #The data will have the following dimensions (time_sequences, batch_size, embed_dim)\n",
        "    x_embed = self.embedding(data)\n",
        "    #-------------#\n",
        "\n",
        "    #-------------#\n",
        "    #packing sequences and passing to RNN unit to save computations\n",
        "    x_packed = pack_padded_sequence(x_embed, lens.cpu(), enforce_sorted = False)\n",
        "    #-------------#\n",
        "\n",
        "    #-------------#\n",
        "    if self.rnn_type == 'LSTM':\n",
        "      #output is packed and cannot be fed to linear layers\n",
        "      output_packed, (hidden,cell) = self.rnn(x_packed) \n",
        "    else:\n",
        "      #For GRU there is only hidden state\n",
        "      output_packed, hidden = self.rnn(x_packed) \n",
        "    #-------------#\n",
        "\n",
        "    #-------------#\n",
        "    #output is padded to be fed to linear layer (padded_lens, batch size, hidden_units)\n",
        "    output_padded, _ = pad_packed_sequence(output_packed)\n",
        "    #-------------#\n",
        "\n",
        "    #-------------#\n",
        "\n",
        "    if self.use_output:\n",
        "        drp = self.drp(output_padded[-1])\n",
        "    else:\n",
        "      drp = self.drp(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1) if self.bi_dir else hidden[-1])\n",
        "    \n",
        "    return self.fc(drp)"
      ],
      "metadata": {
        "id": "TZh1bgauDjMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_WEIGHTS = None\n",
        "RNN_TYPE = 'LSTM'\n",
        "VOCAB_SIZE = len(vocab) \n",
        "N_CLASSES = 1\n",
        "EMBED_SIZE = 128\n",
        "RNN_UNITS = 256\n",
        "N_LAYERS = [1, 2]\n",
        "BI_DIR = [True, False]\n",
        "RNN_DROP = 0.0\n",
        "DROP_RATE = 0.3\n",
        "PADDING_INDEX = vocab['<pad>']"
      ],
      "metadata": {
        "id": "rsrrNUC-GLHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "singleBiDir = IMDBClassifier(VOCAB_WEIGHTS, RNN_TYPE, VOCAB_SIZE, N_CLASSES, EMBED_SIZE, RNN_UNITS, N_LAYERS[0], BI_DIR[1], RNN_DROP, DROP_RATE, PADDING_INDEX)\n",
        "print(f'The total number of trainable parameters for single layered bi-directional LSTM are : {sum(p.numel() for p in singleBiDir.parameters() if p.requires_grad):,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDi_HVv9G7Gj",
        "outputId": "ad8f5afb-4da6-478c-bd7b-91af3a94d4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of trainable parameters for single layered bi-directional LSTM are : 2,955,777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twoBiDir = IMDBClassifier(VOCAB_WEIGHTS, RNN_TYPE, VOCAB_SIZE, N_CLASSES, EMBED_SIZE, RNN_UNITS, N_LAYERS[1], BI_DIR[1], DROP_RATE, DROP_RATE, PADDING_INDEX)\n",
        "print(f'The total number of trainable parameters for two layered bi-directional LSTM are : {sum(p.numel() for p in twoBiDir.parameters() if p.requires_grad):,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s8TtxnFHX7e",
        "outputId": "48521b3d-3efb-481f-89e2-33e2a2757dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of trainable parameters for two layered bi-directional LSTM are : 3,482,113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(singleBiDir.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "singleBiDir = singleBiDir.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "CAZpFe6kIpH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def binary_accuracy(preds, true):\n",
        "  return (((preds >= 0.5) == (true == True)).sum().float())/len(true)\n",
        "\n",
        "def train(model, iterator = trainDataloader, loss_fn = criterion, optimizer = None):\n",
        "  e_loss = e_acc = i = 0\n",
        "  model.train()\n",
        "  for inputs, leng, labels in iterator:\n",
        "    inputs, leng, labels = inputs.to(device), leng.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(inputs, leng).squeeze(1)\n",
        "    loss = loss_fn(preds\n",
        "                   , labels.float())\n",
        "    acc = binary_accuracy(preds, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    e_loss += loss.item()\n",
        "    e_acc += acc.item()\n",
        "    i += 1\n",
        "  return e_loss/i, e_acc/i\n",
        "\n",
        "def predict(model, iterator = testDataloader, loss_fn = criterion):\n",
        "  e_loss = e_acc = i = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for inputs, leng, labels in iterator:\n",
        "      inputs, leng, labels = inputs.to(device), leng.to(device), labels.to(device)\n",
        "      preds = model(inputs, leng).squeeze(1)\n",
        "      loss = loss_fn(preds, labels.float())\n",
        "      acc = binary_accuracy(preds, labels)\n",
        "      e_loss += loss.item()\n",
        "      e_acc += acc.item()\n",
        "      i += 1\n",
        "  return e_loss/i, e_acc/i"
      ],
      "metadata": {
        "id": "VoLGo3OxIcXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(singleBiDir, optimizer = optimizer)\n",
        "    valid_loss, valid_acc = predict(singleBiDir)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} / {N_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzRxg84fInPJ",
        "outputId": "b84427d2-b151-4dae-f063-3ef22eb0ee8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 / 10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.19%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 50.29%\n",
            "Epoch: 02 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.681 | Train Acc: 52.68%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 51.47%\n",
            "Epoch: 03 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.641 | Train Acc: 57.04%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 53.11%\n",
            "Epoch: 04 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.581 | Train Acc: 61.01%\n",
            "\t Val. Loss: 0.749 |  Val. Acc: 52.96%\n",
            "Epoch: 05 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.526 | Train Acc: 63.63%\n",
            "\t Val. Loss: 0.810 |  Val. Acc: 53.35%\n",
            "Epoch: 06 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.503 | Train Acc: 64.59%\n",
            "\t Val. Loss: 0.891 |  Val. Acc: 53.32%\n",
            "Epoch: 07 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.496 | Train Acc: 64.79%\n",
            "\t Val. Loss: 0.975 |  Val. Acc: 52.89%\n",
            "Epoch: 08 / 10 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.499 | Train Acc: 64.67%\n",
            "\t Val. Loss: 0.971 |  Val. Acc: 53.13%\n",
            "Epoch: 09 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.499 | Train Acc: 64.62%\n",
            "\t Val. Loss: 1.009 |  Val. Acc: 52.98%\n",
            "Epoch: 10 / 10 | Epoch Time: 0m 19s\n",
            "\tTrain Loss: 0.496 | Train Acc: 64.74%\n",
            "\t Val. Loss: 1.015 |  Val. Acc: 53.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(twoBiDir.parameters())\n",
        "twoBiDir = twoBiDir.to(device)\n",
        "\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(twoBiDir, optimizer = optimizer)\n",
        "    valid_loss, valid_acc = predict(twoBiDir)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} / {N_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJqmNncQJC0S",
        "outputId": "8d7285ff-68c4-49b2-a787-53aa7a92cb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.694 | Train Acc: 50.08%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 50.64%\n",
            "Epoch: 02 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.689 | Train Acc: 51.00%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 50.06%\n",
            "Epoch: 03 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.678 | Train Acc: 53.37%\n",
            "\t Val. Loss: 0.692 |  Val. Acc: 50.00%\n",
            "Epoch: 04 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.671 | Train Acc: 53.79%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 52.57%\n",
            "Epoch: 05 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.616 | Train Acc: 59.08%\n",
            "\t Val. Loss: 0.691 |  Val. Acc: 54.71%\n",
            "Epoch: 06 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.573 | Train Acc: 61.56%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 55.85%\n",
            "Epoch: 07 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.536 | Train Acc: 63.21%\n",
            "\t Val. Loss: 0.721 |  Val. Acc: 55.13%\n",
            "Epoch: 08 / 10 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.519 | Train Acc: 63.98%\n",
            "\t Val. Loss: 0.780 |  Val. Acc: 55.86%\n",
            "Epoch: 09 / 10 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.512 | Train Acc: 64.18%\n",
            "\t Val. Loss: 0.889 |  Val. Acc: 55.61%\n",
            "Epoch: 10 / 10 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.498 | Train Acc: 64.67%\n",
            "\t Val. Loss: 0.899 |  Val. Acc: 55.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twoBiDirHidden = IMDBClassifier(VOCAB_WEIGHTS, RNN_TYPE, VOCAB_SIZE, N_CLASSES, EMBED_SIZE, RNN_UNITS, N_LAYERS[1], BI_DIR[1], DROP_RATE, DROP_RATE, PADDING_INDEX, use_output= False)\n",
        "print(f'The total number of trainable parameters for two layered bi-directional LSTM are : {sum(p.numel() for p in twoBiDirHidden.parameters() if p.requires_grad):,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z6BroJ3J8PH",
        "outputId": "e79fe43e-b9be-42a4-e58c-9472e7a9b420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of trainable parameters for two layered bi-directional LSTM are : 3,482,113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(twoBiDirHidden.parameters())\n",
        "twoBiDirHidden = twoBiDirHidden.to(device)\n",
        "\n",
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(twoBiDirHidden, optimizer = optimizer)\n",
        "    valid_loss, valid_acc = predict(twoBiDirHidden)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} / {N_EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74AQSaIALEWp",
        "outputId": "f1718e92-44c4-4a4c-bed6-2c66214e658e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 / 10 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.662 | Train Acc: 56.23%\n",
            "\t Val. Loss: 0.580 |  Val. Acc: 66.91%\n",
            "Epoch: 02 / 10 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.465 | Train Acc: 77.61%\n",
            "\t Val. Loss: 0.421 |  Val. Acc: 82.44%\n",
            "Epoch: 03 / 10 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.324 | Train Acc: 86.11%\n",
            "\t Val. Loss: 0.350 |  Val. Acc: 83.24%\n",
            "Epoch: 04 / 10 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.234 | Train Acc: 90.78%\n",
            "\t Val. Loss: 0.363 |  Val. Acc: 84.64%\n",
            "Epoch: 05 / 10 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.181 | Train Acc: 92.91%\n",
            "\t Val. Loss: 0.366 |  Val. Acc: 85.81%\n",
            "Epoch: 06 / 10 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.123 | Train Acc: 95.65%\n",
            "\t Val. Loss: 0.432 |  Val. Acc: 85.97%\n",
            "Epoch: 07 / 10 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.079 | Train Acc: 97.44%\n",
            "\t Val. Loss: 0.501 |  Val. Acc: 85.44%\n",
            "Epoch: 08 / 10 | Epoch Time: 0m 26s\n",
            "\tTrain Loss: 0.063 | Train Acc: 97.85%\n",
            "\t Val. Loss: 0.513 |  Val. Acc: 84.33%\n",
            "Epoch: 09 / 10 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.048 | Train Acc: 98.41%\n",
            "\t Val. Loss: 0.650 |  Val. Acc: 85.04%\n",
            "Epoch: 10 / 10 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.37%\n",
            "\t Val. Loss: 0.751 |  Val. Acc: 84.71%\n"
          ]
        }
      ]
    }
  ]
}